---

loss:
  - target: labels
    name: categorical_crossentropy

train:
  data:
    - mnist:
        images:
          checksum: 440fcabf73cc546fa21475e81ea370265605f56be210a4024d2ca8f203523609
          path: "/Users/Natsume/Downloads/data_for_all/MNIST"
        labels:
          checksum: 3552534a0a558bbed6aed32b30c495cca23d567ec52cac8be1a0730e8010255c
          path: "/Users/Natsume/Downloads/data_for_all/MNIST"

  provider:
    num_batches: 1
  log: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist-log # remember if don't set log, your model won't build on previous runs
  # How many epochs to train for.
  epochs:
    number: 1
    mode: additional
  weights: # the folders below are prepared automatically?
    initial: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.best.valid.w
    best: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.best.train.w
    last: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.last.w
  hooks:
    - plot_weights:
        # layer_index: [1,2] # flatten 1, dense 2, softmax 3
        plot_every_n_epochs: 1
        plot_directory: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist_plot_weights
        weight_file: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.best.valid.w
        with_weights:
          - ["kernel", "dense"]
          - ["weight", "dense"]
        # we can't plot relu weights, cos it does not have weights
        # but we can plot relu's layer output 
        #   - ["weight", "relu"]
        #   - ["kernel", "relu"]

validate: &validate
  data:
    - mnist:
        images:
          url: "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz"
          checksum: 8d422c7b0a1c1c79245a5bcf07fe86e33eeafee792b84584aec276f5a2dbc4e6
          path: "/Users/Natsume/Downloads/data_for_all/MNIST"
        labels:
          url: "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
          checksum: f7ae60f92e00ec6debd23a6088c31dbd2371eca3ffa0defaefb259924204aec6
          path: "/Users/Natsume/Downloads/data_for_all/MNIST"

  # Let's also use less data for validation, just to speed it along.
  provider:
    num_batches: 32

  # Where to save the model weights that have the lowest validation loss.
  weights: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.best.valid.w

# Let's define the test set, used if you execute something like:
# $ kur test mnist.yml
# The funky "*validation" is just a YAML alias, so we basically are setting the
# "test" section" to be the same as the "validate" section.
test: *validate

# This is the evaluation section, used during `kur evaluate mnist.yml`.
# The funky "<<: *validate" is just YAML, and basically means "copy all of the
# keys from 'validate', and then add/replace the
evaluate:
  <<: *validate

  # Use the entire testing set for evaluation.
  provider:
    num_batches: null

  # Where do we want to store the output file?
  # Here, we are just storing it as a Python pickle.
  destination: /Users/Natsume/Downloads/temp_folders/5_classifier_example/mnist.results.pkl

  # This is a list of post-processing hooks. Here, we want to produce the
  # digit-by-digit accuracy table (just called "mnist").
  hooks:
    - mnist
...
