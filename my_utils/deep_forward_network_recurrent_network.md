# deep_forward_network, recurrent_network

## Key points
neuralNet
- start from random weights
- use 1. data (X, y), 2. loss function, 3. learning algo
- to create as similar as truth function to produce y from X

deep_forward_network
- from X to y
- apply loss function on y_pred and y_true
- use loss and learning algo to update weights (no more random values)
- updated weights make network closer to true function

recurrent_network
- same to deep_forward_network
- but recurrent_network will use y_pred as additional input

## Notes in images
![](https://lh3.googleusercontent.com/T1i7XioLuXoPfh1L75Hxrr9GsnzXA-EgzpCDfshr3e1pBhPBeVfM1tTgq_EHYbSEnG38yTtZ4VzVrwugb1qvPWy1xYWUYpVBehvkmpNWLhVauZsLq3SM06Z8ntZiUMGuOXniI_aaiGR4sTlD4J8jpQRpY50wX-lzaJaDEIGd2eAl2K0XFzX_eMb6eGSeqBzTUAgY22UcrMTRBgExkRhrGL1pk73EbidK3ChbbXyk2DAVr79Qiz1VYkATJx6h7K6Ds6exlgQx_D5OVXyK2bpVRIfBOa6wEjIoCIzUY8DvcoijShlkc1KUQcEb2ImzcXhxyHkTpStv_xsT-EHChKXUwelXfIlB_YK-AypvUCX3yIZCu6xLQL-BzeiDaF2yZA44zpdjblkzmzWvobqxHjnCJXGVYjaUrqutPO3ZAkxIsahIm6v8AIjvR6zok79hAXJhCf2cUOtbztkFxJMc2PsT9OVGbKffp_uz7aE00HmDU7qjV34oVNHZTvquFHYtF__X-r615wwKuBWLlgzxiyqGOWn0v4q14ITQ8GdBdpVkQOrqz8yXjJ4UhLoI0zgDQQQ7yh5Fje4u_CWvHb_dLCUP4JXVpepZJTP7j_tAShufJQl5fvNq67WoaccP=w736-h1136-no)
